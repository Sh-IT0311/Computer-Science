# 운영체제

Q. 운영체제란 무엇인가?
<br>A. 하드웨어를 효율적으로 관리하고 사용자 또는 애플리케이션에게 서비스를 제공하는 소프트웨어입니다.

<br>Q. 커널이란 무엇인가?
<br>A. 메모리에 상주하고 있는 운영체제의 부분을 커널이라고 합니다. 운영체제의 크기가 크기 때문에 필요한(필수적인) 부분만 메모리에 상주하고 있는 것입니다.

<br>Q. 프로그램이란?
<br>A. 명령어 코드 및 정적인 데이터의 묶음을 의미합니다.

<br>Q. 바운드(Bound)란?
<br>A. 프로그램이 실행될 때 특정 상황에 의해 실행속도가 제한되는 경우를 말합니다. 예를 들어 복잡한 수식 연산과 같이 CPU 속도에 의해 제한 받는 경우를 CPU 바운드, 키보드로 입력을 받거나 통신을 할 때와 같이 I/O에 의해 제한 받는 경우를 I/O 바운드라고 합니다. 그 밖에 메모리 바운드와 캐시 바운드가 있습니다.

* +) 메모리 바운드 : 사용 가능한 메모리 양과 메모리 엑세스 속도에 영향을 받음
* +) 캐시 바운드 : 사용 가능한 캐시의 양과 액세스 속도에 영향을 받음

<br>Q. blocking과 non-blocking?
<br>A.
* blocking
    * 바운드에 의해 프로그램 실행이 멈추는 현상이 일어나는 것
    * 호출된 함수(동기 함수)가 자신의 할 일을 모두 마칠 때까지 제어권(실행권)을 계속 가지고서 호출한 함수에게 제어권을 바로 돌려주지 않는 것
* non-blocking
    * 바운드에 의해 프로그램 실행이 멈추는 현상이 일어나지 않는 것
    * 호출된 함수(비동기 함수)가 자신이 할 일을 마치지 않았더라도 바로 제어권(실행권)을 건네주어 호출한 함수가 다른 일을 진행 할 수 있도록 하는 것

<br>Q. 동기(Sync)와 비동기(Acync)?
<br>A.
* 동기(Sync)
    * 코드가 작성된 순서 그대로 실행되는 것
    * 호출된 함수의 수행 결과 및 종료를 호출한 함수가 신경을 쓰는 것
* 비동기(Async)
    * 코드가 작성된 순서 그대로 실행되지 않는 것
    * 호출된 함수의 수행 결과 및 종료를 호출된 함수 혼자 신경 쓰는 것

<br>Q. 동시성(Concurrency)과 병렬성(Parallelism)?
<br>A.
* 동시성(Concurrency)
    * 한번에 여러 작업들을 동시적으로 다룸
    * I/O 바운드를 대응하는데 응용됨
    * 여기서 동시적이라는 의미는 논리적인 개념으로, 실제 같은 시간에 모든 것이 다루어지는 것은 아님
    * 싱글 스레드 + 비동기 코드 또는 멀티 스레드 + 동기 코드로 구현가능함
* 병렬성(Parallelism)
    * 멀티코어 시스템에서 한번에 여러작업을 병렬적으로 처리함
    * CPU 바운드를 대응하는데 응용됨
    * 여기서 병렬적이라는 의미는 물리적인 개념으로, 실제 같은 시간에 모든 것이 처리 되는 것을 의미함
    * 멀티프로세싱 뿐만 아니라 멀티스레딩도 병렬성을 만족하도록 구현 할 수 있음

<br>Q. 프로세스란? 프로그램을 멀티프로세스로 구성하면?
<br>A.
* 프로세스
    * 메모리를 할당 받아 실행되고 있는 프로그램
    * PCB를 할당 받고 커널에 의해 관리를 받는 개체
    * 프로세스는 운영체제 관점에서 최소 작업 단위
* 멀티 프로세스
    * 하나의 프로그램에서 하나의 프로세스를 자식 프로세스들로 복제하여 각 프로세스가 1개의 작업을 처리하도록 하는 것을 의미하는 것으로, 각 프로세스는 독립된 메모리(논리메모리, 가상메모리) 영역을 할당 받습니다.
    * 장점
        * 각 프로세스가 독립적으로 실행되기 때문에 다른 프로세스에 발생한 문제에 대해서 영향을 주지 않음
        * 동기화 작업에 대해서 상대적으로 (멀티 스레드와 비교해서) 자유로움
    * 단점
        * (process) context switching을 위한 overhead가 큼
        * 자원 소모적임(개별 메모리)
        * 다른 프로세스의 자료에 직접적으로 접근 할 수 없어서 프로세스 간 통신(Inner-Process Communication, IPC)을 통해 데이터를 주고 받아야됨

<br>Q. IPC(Inter-Process Communication)이란?
<br>A. 프로세스 간에 직접적인 통신이 안되기 때문에 사용되는 기법입니다.
* File : 텍스트 파일을 통해 데이터를 주고 받음
* Pipe : 단방향 통신, 부모 프로세스 -> 자식 프로세스에게 일방적으로 하는 통신
* Message Queue : 프로세스 간에 동일한 키를 가지고 있는 경우, 프로세스 간에 이루어지는 양방향 통신
* Shared Memory : 모든 프로세스가 커널 공간을 공유하는데, 커널 공간에 메모리 공간을 만들고 해당 공간을 변수처럼 사용하는 방식
* Signal : 커널 혹은 프로세스에서 다른 프로세스에게 어떤 이벤트가 발생되었는지를 알려주는 기법
* Socket : 네트워크 통신을 활용한 기법으로, 하나의 컴퓨터 안에서 프로세스 간의 통신을 할 수 있음

<br>Q. 스레드란? 프로그램을 멀티 스레드로 구성하면?
<br>A.
* 스레드
    * 한 프로세스 내에서 나뉘어진 하나 이상의 실행단위
    * 스레드는 프로세스 입장에서 최소 작업 단위
    * CPU(코어)가 처리하는 작업의 단위
* 멀티 쓰레드
    * 하나의 프로그램을 여러 개의 스레드로 구성하여 각 스레드가 1개의 작업을 처리하도록 하는 것을 의미하는 것으로, 스레드 간에 프로세스 내에 Code, Data, Heap 영역은 공유하고 Stack 영역은 따로 할당 받습니다.
    * 장점
        * (thread) context switching을 위한 overhead가 작음
        * 스레드 간에 메모리를 공유하기 때문에 통신에 용이함
        * 자원을 공유하기 때문에 메모리 측면에서 효율적임
    * 단점
        * 동기화 작업에 대해서 상대적으로(멀티 프로세스와 비교해서) 신경을 많이 써야됨
            * ex> data 영역(다른 스레드와 공유)의 전역변수
        * 스레드간 메모리를 공유하기 때문에 하나의 스레드에서 오류가 발생하면 프로세스가 종료될 수 있음


<br>Q 사용자 수준(=레벨) 스레드?, 커널 수준(=레벨) 스레드?
<br>A. Background) 두 종류의 스레드는 어떠한 프로세스 내에 맵핑된 형태로 동시에 존재하며 커널의 통제가 필요한 경우 커널 수준 스레드로, 커널의 통제가 필요 없는 경우 사용자 수준 스레드로 스위칭해가며 작업을 처리하는 형태를 띄고 있습니다. 여기서 맵핑 관계는 상황에 따라 일대일 또는 다대일 등으로 맵핑된 형태가 존재합니다.(그림참조)
* 커널 수준(=레벨) 스레드
    * 커널 레벨에서 생성되어 커널이 직접 관리하는 스레드
* 사용자 수준(=레벨) 스레드
    * 스레드를 관리하는 라이브러리에 의해 사용자 레벨에서 생성 및 관리되는 스레드
* 일대일 모델(커널 수준 스레드를 적극 활용하고자 할 때)
    * 장점
        * 멀티코어 시스템에서 병렬적인 처리를 할 수 있음
        * 특정 스레드가 Blocking이 되어도 다른 스레드들은 독립적으로 작업을 처리할 수 있음
    * 단점
        * 커널 수준의 동작들로 인해 전반적으로 Overhead가 큼
* 다대일 모델(사용자 수준 스레드 > 커널 수준 스레드,사용자 수준 스레드를 적극 활용하고자 할 때)
    * 장점
        * 커널에 독립적으로 스케줄링을 할 수 있어서 유연한 스케줄링이 가능함
    * 단점
        * 멀티코어 시스템에서 병렬적인 처리를 할 수 없음
        * 특정 스레드가 Blocking이 되면 모든 스레드가 멈추는 상황이 발생함


<br>Q. 스레드 풀?
<br>A. 스레드를 생성 및 소멸시키는 것은 시스템에 많은 부담을 제공합니다. 그래서 재사용할 수 있는 스레드를 미리 생성해놓고 필요할 떄 가져다가 사용할 수 있도록 하는 것이 스레드 풀입니다.

<br>Q. 좀비 프로세스? 고아 프로세스?
<br>A.
* 좀비 프로세스
    * 부모 프로세스보다 먼저 종료된 자식 프로세스의 종료 상태를 회수하지 않아 메모리상에서 자식 프로세스의 대한 정보가 사라지지 않은 상태를 지칭하는 용어입니다. 부모 프로세스가 wait 시스템 콜을 호출하여 좀비 프로세스의 종료 상태를 회수하면 좀비 프로세스는 종료됩니다.
* 고아 프로세스
    * 부모 프로세스가 먼저 종료된 자식 프로세스를 지칭하는 용어입니다. 고아 프로세스의 새로운 부모 프로세스로 init 프로세스를 지정하여, init 프로세스가 wait 시스템 콜을 호출하여 고아 프로세스의 종료 상태를 회수해서 좀비 프로세스가 되는 것을 방지합니다.

<br>Q. 작업? job? task?
<br>A.
* 작업 : (처리하고자 하는) 일 정도로 해석해도 무방합니다.
* job : program과 같은 뜻으로 해석해도 무방 합니다.
* task : 일반적으로는 process로 해석해도 무방하나 구체적으로는 작업의 최소단위로써, 상황에 따라 Thread 또는 Process로 해석 됩니다.

<br>Q. PCB(Process Control Block) +) TCB(Thread Control Block)?
<br>A. PCB는 특정 프로세스에 대한 중요한 정보를 저장하고 있는 자료구조로 프로세스의 생성과 동시에 생성됩니다. Single Thread 기반 프로세스의 경우 PCB가 PC와 Register 값을 저장하고 있지만, Multi Thread 기반 프로세스의 경우 TCB가 해당 정보를 가지고 있습니다.

<br>Q. 스택을 스레드마다 독립적으로 할당하는 이유?
<br>A. 스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값, 함수 내에서 선언하는 변수 등을 저장하는 메모리 공간으로, 실행흐름을 저장하고 있다고 해석할 수 있습니다. 스레드의 정의가 프로세스 내에서 나뉘어진 독립적인 실행 단위로, 이러한 독립적인 실행 흐름을 위해 독립적인 스택을 할당하였습니다.

<br>Q. PC register를 스레드마다 독립적으로 할당하는 이유?
<br>A. 각 스레드는 CPU를 할당 받았다가 스케줄러에 의해 다시 선점당하기 때문에 명령어를 어디까지 수행하였는지 기억하기 위해 독립적인 PC 레지스터를 할당 받습니다.

<br>Q. Context?
<br>A. CPU가 해당 프로세스를 실행하기 위한 해당 프로세스/스레드의 정보로, 구체적으로 CPU의 레지스터 값을 의미합니다.

<br>Q. context swiching?
<br>A. 하나의 프로세스가 CPU를 사용중인 상태에서 다른 프로세스가 CPU를 사용하도록 이전의 프로세스의 상태(또는 context)를 저장하고 새로운 프로세스의 상태를 적재하는 작업입니다. 여기서 프로세스의 상태는 PCB에 저장되어 있습니다.

<br>Q. interrupt(인터럽트)?
<br>A. 하나의 프로세스가 CPU를 사용중인 상태에서 예외 상황이 발생하여 프로세스를 멈추고 예외 상황을 처리하는 것을 의미합니다.
* 인터럽트 과정 : interrupt 발생 -> context 저장 -> interrupt handling(원인 파악 및 인터럽트 서비스 할 것인지 결정) 및 interrupt service(interrupt service rountine 호출) -> context 복구

<br>Q. 스케줄링?
<br>A. 프로세스가 여러 개 있는 반면, 프로세스들이 요구하는 자원은 한정되어 있습니다. 이러한 한정된 자원을 어떻게 할당해줄 것인가에 대한 정책을 스케줄링이라고 합니다.

<br>Q. 프로세스 스케줄링?
<br>A. (코어 1개인)프로세서는 한순간에 하나의 프로세스만 처리할 수 있기 때문에, 어느 순간에 어떤 프로세스가 프로세서를 사용할 수 있게 하는지 결정하는 정책으로, 종류로는 비선점형 스케줄링과 선점형 스케줄링이 있습니다.
* 선점? : 강제로 빼앗을 수 있음을 의미함, 프로세스가 완료되지 않았는데 프로세서를 빼앗김

<br>Q. short-term 스케줄링? mid-term 스케줄링? long-term 스케줄링?
<br>A.
* 발생 빈도에 따라 스케줄링을 구분(분류)한 것을 의미합니다.
* short-term(자주) 스케줄링 : 프로세스 스케줄링이라고도 하며, 프로세서를 할당할 프로세스를 결정하는 것입니다.
* mid-term(종종) 스케줄링 : 메모리에 적재된 프로세스의 수를 동적으로 조절하는 것으로, 이러한 동작을 swap-out이라고 합니다.
* long-term(가끔) 스케줄링 : job-스케줄링이라고도 하며, 메모리가 한정적이기 때문에  job-pool로부터 커널에 등록할 job을 결정하는 것을 의미합니다.

<br>Q. starvation이란?
<br>A. 특정 프로세스가 우선순위가 낮아서 원하는 자원을 계속 할당 받지 못하는 상태입니다.

<br>Q. Aging이란?
<br>A. starvation을 방지하기 위해 사용되는 기술로, 기다리는 시간에 비례하여 우선순위를 수정하여 자원을 할당 받을 수 있도록 하는 기술입니다.

<br>Q. 우리가 만든 코드가 실행되기 까지?
<br>A. 소스코드가 컴파일러에 의해 컴파일(기계어로 번역)하여 오브젝트 파일(모듈)이 생성됩니다. 이러한 오브젝트 파일은 라이브러리를 포함하고 있는 다른 오브젝트 파일과 함께 링커를 통해 링킹(오브젝트 파일을 묶어줌) 과정을 거쳐서 실행 파일로 만들어집니다. 이러한 실행 파일은 로더를 통해 로딩(메모리에 올려줌) 과정을 통해 메모리에 올라가 우리의 소스코드가 실행되게 됩니다.

+) complie time(complie), load time(linking ~ loading), run time(실행 중)

<br>Q. 논리(가상)주소? 물리주소? binding?
<br>A. 논리(가상)주소는 CPU가 생성(생각)하는 주소이고, 물리주소는 물리 메모리가 취급하는 주소입니다. binding은 논리주소를 물리주소로 맵핑하는 것을 의미합니다.

<br>Q. binding의 종류?
<br>A. binding 시점에 따라서 종류를 나누었습니다. 컴파일 시점에 바인딩 하는 것을 컴파일 타임 바인딩이라고 하는데, 프로그램 내부에 사용하는 주소와 물리 주소가 똑같습니다. 로드 타임 바인딩은 컴파일 시점에 메모리의 적재 위치를 모르기 때문에 메모리의 시작을 0번부터 하는 상대 주소를 사용하고, 로드 시점에 적재 되는 위치를 알아내게 되면, 시작 주소를 반영하여 상대주소를 실제 물리주소로 맵핑하게 됩니다. 여기서 컴파일 타임 바인딩과 로드 타임 바인딩은 프로그램 전체가 메모리에 올라가야하는 것을 전제하고 있습니다.
<br>
런타임 (실행시간) 바인딩은 런타임 시점에 적재 위치가 정해지며, MMU(Memory Management Unit)를 통해 실제 물리주소로 맵핑하는 과정을 겪습니다. 가상메모리가 이러한 런타임 바인딩을 합니다.

<br>Q. 가상메모리란 무엇인가?
<br>A. 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 메모리 관리 기술로, 프로세스 실행에 필요한 메모리 블록(page in paging system, segmentation in segmentation system)은 메인 메모리에 적재하고, 나머지 블록들은 Swap 메모리에 적재함으로써 구현된 기술입니다. 그래서 프로그램이 물리 메모리의 제약(크기 측면)에서 벗어나고, 각 프로세스들이 더 작은 메모리를 차지 하기 때문에 더 많은 프로세스를 동시 수행가능하게 합니다.

* +) 프로그램이 실행 되면 연속된 메모리의 프로세스로 적재 된다고 전제하는데, 이러한 연속된 메모리가 가상메모리(= 논리메모리)를 의미하는 것임

<br>Q. 코드영역, 데이터영역, 스택영역, 힙영역의 역할은?
<br>A.
* 코드 영역은 프로그램의 코드가 저장되는 영역입니다. CPU는 코드영역에서 저장된 명령어를 하나씩 가져가서 처리합니다.
* 데이터 영역은 전역변수와 정적변수가 저장되는 정적 메모리 영역 입니다.
    * 전역변수와 정적변수는 life time은 프로그램이 죽을 때까지로 같음
    * 전역변수와 정적변수는 scope의 차이를 가지고 있음
        * 전역변수는 다른 파일에서 접근 가능함
        * 정적변수는 오직 해당 파일내에서 scope에 맞게 접근이 가능함
* 힙 영역은 사용자에 의해 메모리 공간이 동적으로 할당되고 해제되는 영역입니다. 런 타임 때 크기가 결정됩니다.
* 스택 영역은 함수 호출 시 전달되는 인자, 되돌아갈 주소값, 함수 내에서 선언하는 변수 등을 저장되는 임시 메모리 영역입니다. 컴파일 타임 때 크기가 결정됩니다.

<br>Q. swap memory(swap area, swap device, swap space)?
<br>A. 물리메모리가 부족할 경우를 대비해서 보조 기억 장치에 만들어 놓은 공간입니다.

<br>Q. swapping?
<br>A. 메인 메모리에 적재한 하나의 프로세스와 Swap 메모리에 적재한 다른 프로세스의 메모리를 교체하는 기법으로 정확히는, 교체의 주체가 가상메모리 개념에서는 메모리 블록(page in paging system, segmentation in segmentation system)이고, 일반적인 정의는 프로세스가 교체의 주체가 됩니다. 더불어 교체하는 과정에서 메인 메모리에 있는 프로세스를 Swap 메모리로 내보내는 것을 Swap-out, Swap 메모리에 존재하는 프로세스를 메인 메모리에 적재하는 것을 Swap-in 이라고 합니다.

<br>Q. paging system?
<br>A. 프로세스의 논리메모리를 일정한 크기의 페이지로 분할해서 물리 메모리에 적재하는 방법으로, 가상 주소와 물리 주소간 매핑 정보를 담고 있는 페이지 테이블을 통해 물리 주소를 알아냅니다. 이러한 페이지 테이블은 PCB에 저장되어 있습니다.

* +) 가상주소 = 페이지 번호 + 변위
    * ex> 0x001FFFF -> 001F는 페이지 번호, FFF는 변위로 해석
* +) 페이지 테이블에는 첫 물리 주소를 가지고 있고, 변위를 통해 MMU로 실제 물리 주소를 계산함
* +) 메인 메모리는 page frame으로 분할됨

<br>Q. page fault?
<br>A. 프로세스가 사용하려고 하는 page가 메인 메모리에 없는 경우를 말하는데 페이지 테이블에 존재하는 valid bit를 통해 알 수 있습니다. 이러한 페이지 폴트가 일어 났을 경우 Swap 메모리에서 해당 페이지를 메인 메모리에 적재하며, 페이지 테이블을 갱신하고, 실제 물리 주소를 계산해 접근하게 됩니다.

<br>Q. segmentation system?
<br>A. 프로세스의 논리메모리를 논리적 크기(블록마다 크기 다름)로 분할한 세그멘테이션을 메모리에 적재하는 방법으로, 가상 주소와 물리 주소간 매핑 정보를 담고 있는 세그멘테이션 테이블을 통해 물리 주소를 알아냅니다. 이러한 세그멘테이션 테이블은 PCB에 저장되어 있습니다.

<br>Q. 단편화? 내부 단편화? 외부 단편화? 해결방법?
<br>A.
* 단편화 : 메모리의 빈 공간이 여러 개의 조각으로 나뉘는 현상으로, 이러한 조각을 합치면 수치상으로는 많은 메모리 공간이 남았음에도 불구하고, 실제로 사용할 수 없는 메모리가 발생합니다.
* 내부 단편화 : 분할된 영역이 할당된 프로그램의 크기보다 커서 사용되지 않고 남아 있는 빈공간을 의미합니다.
* 외부 단편화 : 메모리의 빈공간을 합치면 충분함에도 연속적이지 못해서 메모리를 사용할 수 없는 상황을 의미합니다.
* 해결방법 : 메모리 압축(모든 빈공간을 하나로 통합), 메모리 통합(인접한 빈영역을 통합)

<br>Q. LRU(페이지 교체 알고리즘 중 하나)
<br>A. 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체하는 방법입니다.

<br>Q. 동기화?
<br>A. 한정적인 자원에 여러 프로세스(스레드)가 동시에 접근하면 문제가 발생 할 수 있습니다. 이러한 문제를 방지하기 위해 프로세스(스레드)들에게 하나의 자원에 대한 처리 권한을 주거나 순서를 조정해주는 기법을 동기화라고 합니다.

<br>Q. 상호배제?
<br>A. 여러 프로세스(스레드)가 공유자원에 접근하는 것을 막는 것을 의미합니다.

<br>Q. 공유데이터? 임계영역?
<br>A.
* 공유데이터(shared data) : 여러 프로세스(스레드)들이 공유하고 있는 데이터
* 임계영역(critical section) : 공유데이터를 접근하는 코드 영역(= 부분)
    * 임계영역 문제를 해결하기 위한 3가지 조건
        1. 상호배제 : 한번에 두개 이상의 프로세스가 임계영역에 진입하는 것을 금지하는 것을 의미합니다.
        2. 진행 : 임계영역의 어떤 프로세스의 접근도 없을 때는 항상 접근이 가능하게 하는 것입니다.
        3. 한정 대기 : 프로세스의 임계영역 진입은 유한시간 내에 허용되어야 함

<br>Q. 뮤텍스와 세마포어의 차이?
<br>A.
* 세마포어와 뮤텍스 모두 동기화에 이용됩니다.
* 뮤텍스
    * 임계영역에 접근하기 위해서는 뮤텍스(object)를 획득(= 락)해야만 접근할 수 있고, 획득한 쓰레드 또는 프로세스만 뮤텍스를 해제(unLock)할 수 있는데, 이러한 메커니즘을 Locking 메커니즘으로 호칭하고 있습니다.
    * 또한 공유하고 있는 자원의 갯수가 1개입니다.
* 세마포어
    * 세마포어 변수를 사용하여 임계영역에 접근 하는 것을 통제하는 전반적인 과정이 뮤텍스와 비슷하지만, 락을 걸지 않은 프로세스 혹은 스레드도 signal을 보내 락을 해제 할 수 있는 signaling 메커니즘을 사용하고 있습니다.
    *  뮤텍스와 다르게 1개 이상의 자원을 통제 할 수 있습니다.

<br>Q. 뮤텍스와 세마포어의 차이
<br>A. 공유하고 있는 자원의 갯수 + 메커니즘

<br>Q. 교착상태(DeadLock)란?
<br>A. 두 개 이상의 프로세스나 스레드가 서로 자원을 무한히 기다리는 상태를 말합니다.

<br>Q. 교착상태가 일어나는 4가지 필요 조건은?
<br>A.
* 상호배제 : 여러 프로세스(스레드)가 공유자원에 접근하는 것을 막는 것을 의미함
* 점유와 대기 : 하나의 자원을 점유하고 다른 자원을 점유하기 위해 대기하고 있는 것을 의미함
* 비선점 : 프로세스(스레드)가 자원을 할당 받으면 완료할 때까지 점유하고 있는 것을 의미함
* 순환 대기 : 점유와 대기의 형태가 순환(환형) 구조를 가지고 있는 것을 의미함

<br>Q. 교착 상태 해결 방법은?
<br>A.
* 예방 : 4가지 필요조건 중 하나를 거부하는 것인데, 자원을 효율적으로 사용하지 못하게 하기 때문에 현실적이지 못합니다.
* 회피 : 교착상태를 예상하여 교착상태를 피하는 것으로, 가정들이 현실적이지 못하고 회피 감지를 위한 overhead가 큽니다.
* 탐지 및 복구 : 주기적인 탐지 및 프로세스 종료 및 자원 선점으로 복구하는 방법, 예방, 회피보다는 현실적입니다.
* 무시 : 교착 상태를 신경쓰지 않다가, 교착상태가 발생하면 재부팅 또는 프로세스 종료를 취하는 것으로 앞서 언급한 방법들에 의한 오버헤드 또는 성능 저하를 발생시키는 것보다 더 낫다고 판단하는 것입니다.

<br>Q. 지역성이란?
<br>A. 동일한(인접한) 위치를 자주 액세스 하는 현상으로, 종류로는 시간 지역성과 공간 지역성이 있습니다. 공간적 지역성은 참조한 주소와 인접한 주소를 참조하는 특성을 가지는 지역성이고, 시간적 지역성은 한 번 참조한 주소를 곧 다시 참조하는 특성을 가지는 지역성입니다.

<br>Q. 캐시의 지역성?
<br>A. 캐시는 속도가 빠른 장치와 느린 장치간에 병목현상을 줄이기 위한 메모리입니다. 캐시의 성능은 CPU가 참조할 정보를 어느 정도 가지고 있느냐에 좌우 되는데, 참조할 정보를 가지고 있는 비율을 나타내는 Hit Rate를 극대화 시키기 위해 지역성의 원리가 활용됩니다.